---
title: "Serial dependence in random binary sequences"
date: 2020-04-05
draft: true
katex: true
markup: "mmark"
modified: 2020-04-05
---

In this blog post I am going to investigate serial dependence in random binary sequences.

* Binary sequences are sequences of of zeros and ones. 

It's about binary sequences that flag occurrence of some random events. In this context, we observe a system
at discrete time instances and produce zeros if not event occurred and one otherwise.  

TODO: Describe a simple example and work with in through the article.

## Remarks to be mixed into the text later

* I am interested in the statistical formulation of the problem. Given a finite sequence of zeros and ones, collect 
a set of methods to gather arguments to support or reject the hypothesis that this sequence was generated
by sampling from a Bernoulli random variable with success probability $$p$$.
* Is a given sequence a random noise or is there some underlying pattern. 
* In particular, I am interested in testing whether there is a dependence between the events. Do these events 
tend to occur in clusters? 

## Probabilistic formulation of the problem.

Given a sequence or random variables $$X = (X_0, X_1, ..., X_n)$$ taking values in the set $${0, 1}$$ 
and a probability $$p\in(0,1)$$. Moreover, I have a sample drawn from $$X$$, i.e. a sequence of zeros and ones
$$x_0, x_1, ..., x_n$$. I would like to investigate whether 

1. $$X_i$$ have all the same distribution $$\text{Ber}(p)$$ (check if the occurrence probability is really $$p$$), and
2. whether $$X_i$$ are independent (check if there is a dependence between the events). 

Simpler question: Was the sequence $$x_0, x_1, ..., x_n$$ generated by independent sampling from a 
Bernoulli random variable $$X\tilde\text{Ber}(p)$$.

This is a surprisingly difficult and deep problem.

If we assume that the events are i.i.d. samples from a fixed Bernoulli random variable $$X_0$$, then
we can estimate the probability $$p$$ by calculating the average of $$x_0, x_1, ..., x_n$$. 
This is because the expectation of $$X_0$$ is $$E X_0 = p$$.

## Serial dependence

How can we check whether our events occur independently of each other and rule out dependence. 

Examples of dependent events is when occurrence of an event some how impacts the occurrence 
probabilities of subsequent events. Typical example is when something breaks and gets repaired. 

Lucky and unlucky streaks. Run of luck. Winning streak. 

Mention the problem of run probabilities and the our intuitive understanding of independence is often not correct.

In order to investigate the serial dependence between the occurrence times I can calculate the time
distances between the events. 


## Examples

* VaR violations. 
* Random number generators usually produce binary sequences that are transformed deterministically into some
"more interesting" random numbers. There are test suites that test how random is a sequence produced by a rng. 
Example: Die hard test suite.
* Kaggle competitions or data sets?

## Use cases

* Value at Risk testing. 

## Ideas

* Train a Markov process and look at it's transition probability matrix.


## References

* Bertrand Candelon, Gilbert Colletaz, Christophe Hurlin, Sessi Tokpavi, 
  Backtesting Value-at-Risk: A GMM Duration-Based Test, Journal of Financial Econometrics, Volume 9, Issue 2, Spring 2011, Pages 314â€“343, http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.404.3188&rep=rep1&type=pdf
* Christoffersen, Peter and Pelletier, Denis, Backtesting Value-at-Risk: A Duration-Based Approach (January 31, 2003). Available at SSRN: https://ssrn.com/abstract=418762 or http://dx.doi.org/10.2139/ssrn.418762 



